{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection to the database\n",
    "client = MongoClient()\n",
    "\n",
    "db_name = \"PoliceShootings\"\n",
    "\n",
    "# Drop database if it exists\n",
    "if db_name in client.list_database_names():\n",
    "    client.drop_database(db_name)\n",
    "\n",
    "db = client[db_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Read CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder = \"archive\"\n",
    "\n",
    "completed_highschool_df = pd.read_csv(f\"{csv_folder}/PercentOver25CompletedHighSchool.csv\", encoding=\"ISO-8859-1\")\n",
    "police_killings_df = pd.read_csv(f\"{csv_folder}/PoliceKillingsUS.csv\", encoding=\"ISO-8859-1\")\n",
    "race_by_city_df = pd.read_csv(f\"{csv_folder}/ShareRaceByCity.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the database and collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.create_collection(\"State\")\n",
    "state_col= db['State']\n",
    "\n",
    "db.create_collection(\"City\")\n",
    "city_col = db['City']\n",
    "\n",
    "db.create_collection(\"Race\")\n",
    "race_col = db['Race']\n",
    "\n",
    "db.create_collection(\"PercentOver25CompletedHighSchool\")\n",
    "percent_highschool_col = db['PercentOver25CompletedHighSchool']\n",
    "\n",
    "db.create_collection(\"PoliceKillings\")\n",
    "killings_col = db['PoliceKillings']\n",
    "\n",
    "db.create_collection(\"ShareRaceByCity\")\n",
    "share_race_city_col = db['ShareRaceByCity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replaces redundent words with empty string\n",
    "def remove_redundency(dataframe):\n",
    "    dataframe['City'] = dataframe['City'].str.replace(' town', '')\n",
    "    dataframe['City'] = dataframe['City'].str.replace(' city', '')\n",
    "    dataframe['City'] = dataframe['City'].str.replace(' CDP', '')\n",
    "\n",
    "# Map race Acronym to race string\n",
    "char_to_race = {\n",
    "    \"W\": \"white\",\n",
    "    \"B\": \"black\",\n",
    "    \"N\": \"native_american\",\n",
    "    \"A\": \"asian\",\n",
    "    \"H\": \"hispanic\",\n",
    "    \"O\": \"other\",\n",
    "}\n",
    "\n",
    "def convert_string_to_race(acronym):\n",
    "    if not isinstance(acronym, str):\n",
    "        return None\n",
    "    return char_to_race[acronym]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the city, town, CDP suffixes for less issues with connecting collections\n",
    "remove_redundency(completed_highschool_df)\n",
    "remove_redundency(race_by_city_df)\n",
    "\n",
    "# Renaming the values of race for creating the relationships with ease\n",
    "police_killings_df[\"race\"] = police_killings_df[\"race\"].apply(convert_string_to_race)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique state names\n",
    "df_state = pd.DataFrame({'acronym': completed_highschool_df[\"Geographic Area\"].drop_duplicates().values})\n",
    "# Set to Column:Value for mongo insertion\n",
    "df_state = df_state.to_dict('records')\n",
    "# Store in variable for possible use after\n",
    "result_state_insertion = state_col.insert_many(df_state) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = state_col.find()\n",
    "dict_state_to_id = {}\n",
    "# Map state to id\n",
    "for doc in docs:\n",
    "    dict_state_to_id[doc['acronym']] = ObjectId(str(doc['_id']))\n",
    "\n",
    "# No unique city names because the same city name can appear for more than one state\n",
    "df_city = pd.DataFrame({'name': completed_highschool_df[\"City\"].values}) \n",
    "df_city['state_id'] = completed_highschool_df[\"Geographic Area\"].map(dict_state_to_id)\n",
    "# Set to Column:Value for mongo insertion\n",
    "df_city = df_city.to_dict('records')\n",
    "# Store in variable for possible use after\n",
    "result_city_insertion = city_col.insert_many(df_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = [\"white\", \"black\", \"native_american\", \"asian\", \"hispanic\", \"other\"]\n",
    "\n",
    "df_race = pd.DataFrame({'name': races})\n",
    "# Set to Column:Value for mongo insertion\n",
    "df_race = df_race.to_dict('records')\n",
    "# Store in variable for possible use after\n",
    "result_race_insertion = race_col.insert_many(df_race) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Percent over 25 completed high school"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = city_col.find()\n",
    "dict_city_to_id = {}\n",
    "# Map city name and state to city id\n",
    "for doc in docs:\n",
    "    dict_city_to_id[(doc['name'], doc['state_id'])] = ObjectId(str(doc['_id']))\n",
    "\n",
    "df_percent_highschool = pd.DataFrame({'percent': completed_highschool_df[\"percent_completed_hs\"].values})\n",
    "df_percent_highschool['city_id'] = completed_highschool_df.apply(lambda x: dict_city_to_id[(x[\"City\"], dict_state_to_id[x[\"Geographic Area\"]])], axis=1)\n",
    "# Set to Column:Value for mongo insertion\n",
    "df_percent_highschool = df_percent_highschool.to_dict('records')\n",
    "# Store in variable for possible use after\n",
    "result_percent_highschool_insertion = percent_highschool_col.insert_many(df_percent_highschool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Police killings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given city and state, return city id\n",
    "def convert_state_and_city_to_id(city, state):\n",
    "  if (city, dict_state_to_id[state]) in dict_city_to_id:\n",
    "    return dict_city_to_id[(city, dict_state_to_id[state])]\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = race_col.find()\n",
    "dict_race_to_id = {}\n",
    "# Map race to its id\n",
    "for doc in docs:\n",
    "    dict_race_to_id[doc['name']] = ObjectId(str(doc['_id']))\n",
    "\n",
    "df_killings = police_killings_df.copy()\n",
    "df_killings.drop(\"race\", axis=1)\n",
    "df_killings.drop(\"state\", axis=1)\n",
    "df_killings.drop(\"city\", axis=1)\n",
    "\n",
    "dates = pd.to_datetime(police_killings_df[\"date\"].values, dayfirst = True)\n",
    "dates = np.array(dates,dtype=np.datetime64)\n",
    "df_killings['race_id'] = police_killings_df[\"race\"].map(dict_race_to_id)\n",
    "df_killings['city_id'] = police_killings_df.apply(lambda x: convert_state_and_city_to_id(x[\"city\"], x[\"state\"]), axis=1)\n",
    "df_killings['date'] = dates\n",
    "df_killings = df_killings.to_dict('records')\n",
    "result_killing_insertion = killings_col.insert_many(df_killings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Share race by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each of the 5 shares: share_white,share_black,share_native_american,share_asian,share_hispanic\n",
    "# have a new row on the dataframe\n",
    "\n",
    "df_city_ids = race_by_city_df.apply(lambda x: convert_state_and_city_to_id(x[\"City\"], x[\"Geographic area\"]), axis=1)\n",
    "\n",
    "df_share_race_city_white = pd.DataFrame({'share': race_by_city_df[\"share_white\"].values})\n",
    "df_share_race_city_white['Race_id'] = dict_race_to_id[\"white\"]\n",
    "df_share_race_city_white['City_id'] = df_city_ids\n",
    "\n",
    "df_share_race_city_black = pd.DataFrame({'share': race_by_city_df[\"share_black\"].values})\n",
    "df_share_race_city_black['Race_id'] = dict_race_to_id[\"black\"]\n",
    "df_share_race_city_black['City_id'] = df_city_ids\n",
    "\n",
    "df_share_race_city_native = pd.DataFrame({'share': race_by_city_df[\"share_native_american\"].values})\n",
    "df_share_race_city_native['Race_id'] = dict_race_to_id[\"native_american\"]\n",
    "df_share_race_city_native['City_id'] = df_city_ids\n",
    "\n",
    "df_share_race_city_asian = pd.DataFrame({'share': race_by_city_df[\"share_asian\"].values})\n",
    "df_share_race_city_asian['Race_id'] = dict_race_to_id[\"asian\"]\n",
    "df_share_race_city_asian['City_id'] = df_city_ids\n",
    "\n",
    "df_share_race_city_hispanic = pd.DataFrame({'share': race_by_city_df[\"share_hispanic\"].values})\n",
    "df_share_race_city_hispanic['Race_id'] = dict_race_to_id[\"hispanic\"]\n",
    "df_share_race_city_hispanic['City_id'] = df_city_ids\n",
    "\n",
    "df_share_race_city = pd.concat(\n",
    "[\n",
    "    df_share_race_city_white, \n",
    "    df_share_race_city_black,\n",
    "    df_share_race_city_native, \n",
    "    df_share_race_city_asian,\n",
    "    df_share_race_city_hispanic\n",
    "])\n",
    "\n",
    "df_share_race_city = df_share_race_city.to_dict('records')\n",
    "result_share_race_city_insertion = share_race_city_col.insert_many(df_share_race_city)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
